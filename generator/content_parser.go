package generator

import (
	"fmt"
	"hugo-content-suite/config"
	"hugo-content-suite/translator"
	"regexp"
	"strings"

	"github.com/tmc/langchaingo/textsplitter"
)

// ParagraphMapping æ®µè½æ˜ å°„ä¿¡æ¯ï¼Œç”¨äºè¿½è¸ªæ‹†åˆ†çš„æ®µè½å…³ç³»
type ParagraphMapping struct {
	OriginalIndex int      // åŸå§‹æ®µè½ç´¢å¼•
	SplitParts    []string // æ‹†åˆ†åçš„éƒ¨åˆ†
	IsOriginal    bool     // æ˜¯å¦ä¸ºåŸå§‹æ®µè½ï¼ˆæœªæ‹†åˆ†ï¼‰
}

// SplitResult æ®µè½æ‹†åˆ†ç»“æœ
type SplitResult struct {
	Paragraphs []string           // æ‹†åˆ†åçš„æ®µè½åˆ—è¡¨
	Mappings   []ParagraphMapping // æ®µè½æ˜ å°„å…³ç³»
}

// ContentParser å†…å®¹è§£æå™¨
type ContentParser struct {
	translationUtils *translator.TranslationUtils
	config           *config.Config
}

// NewContentParser åˆ›å»ºå†…å®¹è§£æå™¨
func NewContentParser() *ContentParser {
	return &ContentParser{
		translationUtils: translator.NewTranslationUtils(),
		config:           config.GetGlobalConfig(),
	}
}

// ParseArticleContent è§£ææ–‡ç« å†…å®¹ï¼Œåˆ†ç¦»å‰ç½®æ•°æ®å’Œæ­£æ–‡
func (c *ContentParser) ParseArticleContent(content string) (string, string) {
	lines := strings.Split(content, "\n")

	if len(lines) < 3 || strings.TrimSpace(lines[0]) != "---" {
		return "", content
	}

	frontMatterEnd := -1
	for i := 1; i < len(lines); i++ {
		if strings.TrimSpace(lines[i]) == "---" {
			frontMatterEnd = i
			break
		}
	}

	if frontMatterEnd == -1 {
		return "", content
	}

	frontMatter := strings.Join(lines[1:frontMatterEnd], "\n") // ä¸åŒ…å«å‰åçš„ ---
	body := strings.Join(lines[frontMatterEnd+1:], "\n")

	return frontMatter, body
}

// ExtractFieldValue æå–å­—æ®µå€¼
func (c *ContentParser) ExtractFieldValue(line, prefix string) string {
	value := strings.TrimSpace(strings.TrimPrefix(line, prefix))
	return strings.Trim(value, "\"'")
}

// ExtractArrayField æå–æ•°ç»„å­—æ®µ
func (c *ContentParser) ExtractArrayField(line, prefix string) []string {
	value := strings.TrimSpace(strings.TrimPrefix(line, prefix))
	value = strings.Trim(value, "[]")

	if value == "" {
		return []string{}
	}

	parts := strings.Split(value, ",")
	var result []string

	for _, part := range parts {
		part = strings.TrimSpace(part)
		part = strings.Trim(part, "\"'")
		if part != "" {
			result = append(result, part)
		}
	}

	return result
}

// FormatArrayField æ ¼å¼åŒ–æ•°ç»„å­—æ®µ
func (c *ContentParser) FormatArrayField(items []string) string {
	if len(items) == 0 {
		return "[]"
	}

	var quotedItems []string
	for _, item := range items {
		cleanItem := item
		// å†æ¬¡ç¡®ä¿ç§»é™¤åŒå¼•å·
		cleanItem = strings.ReplaceAll(cleanItem, "\"", "")
		cleanItem = strings.ReplaceAll(cleanItem, "'", "")
		cleanItem = strings.TrimSpace(cleanItem)
		quotedItems = append(quotedItems, fmt.Sprintf("\"%s\"", cleanItem))
	}

	return fmt.Sprintf("[%s]", strings.Join(quotedItems, ", "))
}

// CombineTranslatedContent åˆå¹¶ç¿»è¯‘åçš„å†…å®¹
func (c *ContentParser) CombineTranslatedContent(frontMatter, body string) string {
	if frontMatter == "" {
		return body
	}
	return frontMatter + "\n\n" + body
}

// AnalyzeArticleContent åˆ†ææ–‡ç« å†…å®¹ç»Ÿè®¡
func (c *ContentParser) AnalyzeArticleContent(content string) (int, int) {
	_, body := c.ParseArticleContent(content)

	// ç»Ÿè®¡å­—æ•°
	wordCount := len(strings.Fields(body))

	// ç»Ÿè®¡æ®µè½æ•°
	paragraphs := c.splitIntoParagraphs(body)
	paragraphCount := len(paragraphs)

	return wordCount, paragraphCount
}

// EstimateTranslationTime ä¼°ç®—ç¿»è¯‘æ—¶é—´
func (c *ContentParser) EstimateTranslationTime(paragraphCount int) string {
	seconds := paragraphCount * 2

	if seconds < 60 {
		return fmt.Sprintf("%dç§’", seconds)
	} else if seconds < 3600 {
		minutes := seconds / 60
		return fmt.Sprintf("%dåˆ†é’Ÿ", minutes)
	} else {
		hours := seconds / 3600
		minutes := (seconds % 3600) / 60
		return fmt.Sprintf("%då°æ—¶%dåˆ†é’Ÿ", hours, minutes)
	}
}

// splitIntoParagraphs å°†æ–‡æœ¬åˆ†å‰²æˆæ®µè½
func (c *ContentParser) splitIntoParagraphs(text string) []string {
	splitter := textsplitter.NewMarkdownTextSplitter()
	paragraphs, err := splitter.SplitText(text)
	if err != nil {
		// å¤„ç†é”™è¯¯
		return []string{}
	}
	return paragraphs
}

// ParseContentIntoParagraphsWithMapping å°†å†…å®¹è§£æä¸ºæ®µè½å¹¶ä¿ç•™æ˜ å°„å…³ç³»
func (c *ContentParser) ParseContentIntoParagraphsWithMapping(content string) (*SplitResult, error) {
	paragraphs := c.splitIntoParagraphs(content)

	// åº”ç”¨æ®µè½æ‹†åˆ†å¹¶ç”Ÿæˆæ˜ å°„å…³ç³»
	return c.applySplittingWithMapping(paragraphs), nil
}

// applySplittingWithMapping å¯¹æ®µè½åˆ—è¡¨åº”ç”¨æ‹†åˆ†å¹¶ç”Ÿæˆæ˜ å°„å…³ç³»
func (c *ContentParser) applySplittingWithMapping(paragraphs []string) *SplitResult {
	var resultParagraphs []string
	var mappings []ParagraphMapping

	for originalIndex, paragraph := range paragraphs {

		// å¯¹æ™®é€šæ®µè½åº”ç”¨æ‹†åˆ†
		splitParagraphs := c.splitLongParagraph(paragraph)
		resultParagraphs = append(resultParagraphs, splitParagraphs...)

		// è®°å½•æ˜ å°„å…³ç³»
		mappings = append(mappings, ParagraphMapping{
			OriginalIndex: originalIndex,
			SplitParts:    splitParagraphs,
			IsOriginal:    len(splitParagraphs) == 1 && splitParagraphs[0] == paragraph,
		})
	}

	result := &SplitResult{
		Paragraphs: resultParagraphs,
		Mappings:   mappings,
	}

	// ç”Ÿæˆå¹¶è®°å½•ç»Ÿè®¡ä¿¡æ¯
	if c.config.Paragraph.EnableSplitting {
		stats := c.GetParagraphSplitStats(paragraphs, resultParagraphs)
		c.LogParagraphSplitInfo(stats)
	}

	return result
}

// MergeTranslatedParagraphs åˆå¹¶ç¿»è¯‘åçš„æ‹†åˆ†æ®µè½
func (c *ContentParser) MergeTranslatedParagraphs(translatedParagraphs []string, mappings []ParagraphMapping) ([]string, error) {
	if !c.config.Paragraph.MergeAfterTranslation {
		// å¦‚æœé…ç½®ä¸ºä¸åˆå¹¶ï¼Œç›´æ¥è¿”å›ç¿»è¯‘åçš„æ®µè½
		return translatedParagraphs, nil
	}

	var mergedParagraphs []string
	var currentIndex int

	for _, mapping := range mappings {
		if mapping.IsOriginal {
			// åŸå§‹æ®µè½æœªè¢«æ‹†åˆ†ï¼Œç›´æ¥æ·»åŠ 
			if currentIndex < len(translatedParagraphs) {
				mergedParagraphs = append(mergedParagraphs, translatedParagraphs[currentIndex])
				currentIndex++
			}
		} else {
			// æ®µè½è¢«æ‹†åˆ†äº†ï¼Œéœ€è¦åˆå¹¶ç¿»è¯‘åçš„ç‰‡æ®µ
			var parts []string
			for i := 0; i < len(mapping.SplitParts); i++ {
				if currentIndex < len(translatedParagraphs) {
					parts = append(parts, strings.TrimSpace(translatedParagraphs[currentIndex]))
					currentIndex++
				}
			}

			if len(parts) > 0 {
				// åˆå¹¶æ‹†åˆ†çš„æ®µè½ä¸ºå•ä¸ªæ®µè½
				merged := strings.Join(parts, " ")
				mergedParagraphs = append(mergedParagraphs, merged)
			}
		}
	}

	return mergedParagraphs, nil
}

// splitLongParagraph æ‹†åˆ†è¿‡é•¿çš„æ®µè½
func (c *ContentParser) splitLongParagraph(paragraph string) []string {
	// å¦‚æœæœªå¯ç”¨æ‹†åˆ†æˆ–æ®µè½ä¸è¶…é•¿ï¼Œç›´æ¥è¿”å›
	if !c.config.Paragraph.EnableSplitting || len(paragraph) <= c.config.Paragraph.MaxLength {
		return []string{paragraph}
	}

	var result []string

	// å¦‚æœå¯ç”¨äº†åœ¨å¥å­è¾¹ç•Œæ‹†åˆ†
	if c.config.Paragraph.SplitAtSentences {
		result = c.splitAtSentenceBoundaries(paragraph)
	} else {
		result = c.splitAtCharacterLimit(paragraph)
	}

	// è¿‡æ»¤æ‰è¿‡çŸ­çš„æ®µè½ç‰‡æ®µ
	var filteredResult []string
	for _, part := range result {
		if strings.TrimSpace(part) != "" && len(strings.TrimSpace(part)) >= c.config.Paragraph.MinSplitLength {
			filteredResult = append(filteredResult, part)
		}
	}

	// å¦‚æœè¿‡æ»¤åæ²¡æœ‰ç»“æœï¼Œè¿”å›åŸæ®µè½
	if len(filteredResult) == 0 {
		return []string{paragraph}
	}

	return filteredResult
}

// splitAtSentenceBoundaries åœ¨å¥å­è¾¹ç•Œæ‹†åˆ†æ®µè½
func (c *ContentParser) splitAtSentenceBoundaries(paragraph string) []string {
	var result []string
	var currentSegment strings.Builder

	// å®šä¹‰å¥å­ç»“æŸæ ‡è®°çš„æ­£åˆ™è¡¨è¾¾å¼
	sentenceEndRegex := regexp.MustCompile(`[.!?ã€‚ï¼ï¼Ÿ]\s*`)

	// æŸ¥æ‰¾æ‰€æœ‰å¥å­ç»“æŸä½ç½®
	matches := sentenceEndRegex.FindAllStringIndex(paragraph, -1)

	if len(matches) == 0 {
		// æ²¡æœ‰æ‰¾åˆ°å¥å­è¾¹ç•Œï¼ŒæŒ‰å­—ç¬¦é™åˆ¶æ‹†åˆ†
		return c.splitAtCharacterLimit(paragraph)
	}

	lastEnd := 0

	for _, match := range matches {
		sentenceEnd := match[1]
		sentence := paragraph[lastEnd:sentenceEnd]

		// æ£€æŸ¥å½“å‰æ®µè½åŠ ä¸Šè¿™ä¸ªå¥å­æ˜¯å¦è¶…è¿‡é•¿åº¦é™åˆ¶
		if currentSegment.Len()+len(sentence) > c.config.Paragraph.MaxLength && currentSegment.Len() > 0 {
			// ä¿å­˜å½“å‰æ®µè½
			if segment := strings.TrimSpace(currentSegment.String()); segment != "" {
				result = append(result, segment)
			}
			currentSegment.Reset()
		}

		currentSegment.WriteString(sentence)
		lastEnd = sentenceEnd
	}

	// å¤„ç†å‰©ä½™éƒ¨åˆ†
	if lastEnd < len(paragraph) {
		remaining := paragraph[lastEnd:]
		if currentSegment.Len()+len(remaining) > c.config.Paragraph.MaxLength && currentSegment.Len() > 0 {
			if segment := strings.TrimSpace(currentSegment.String()); segment != "" {
				result = append(result, segment)
			}
			if remaining := strings.TrimSpace(remaining); remaining != "" {
				result = append(result, remaining)
			}
		} else {
			currentSegment.WriteString(remaining)
		}
	}

	// æ·»åŠ æœ€åçš„æ®µè½
	if segment := strings.TrimSpace(currentSegment.String()); segment != "" {
		result = append(result, segment)
	}

	return result
}

// splitAtCharacterLimit æŒ‰å­—ç¬¦é™åˆ¶æ‹†åˆ†æ®µè½
func (c *ContentParser) splitAtCharacterLimit(paragraph string) []string {
	var result []string
	maxLength := c.config.Paragraph.MaxLength

	// å¦‚æœæ®µè½é•¿åº¦å°äºç­‰äºé™åˆ¶ï¼Œç›´æ¥è¿”å›
	if len(paragraph) <= maxLength {
		return []string{paragraph}
	}

	// æŒ‰ç©ºç™½å­—ç¬¦åˆ†å‰²ä¸ºå•è¯
	words := strings.Fields(paragraph)
	var currentSegment strings.Builder

	for _, word := range words {
		// æ£€æŸ¥æ·»åŠ è¿™ä¸ªå•è¯æ˜¯å¦ä¼šè¶…è¿‡é•¿åº¦é™åˆ¶
		testLength := currentSegment.Len()
		if testLength > 0 {
			testLength += 1 // åŠ ä¸Šç©ºæ ¼
		}
		testLength += len(word)

		if testLength > maxLength && currentSegment.Len() > 0 {
			// ä¿å­˜å½“å‰æ®µè½å¹¶å¼€å§‹æ–°çš„æ®µè½
			if segment := strings.TrimSpace(currentSegment.String()); segment != "" {
				result = append(result, segment)
			}
			currentSegment.Reset()
			currentSegment.WriteString(word)
		} else {
			if currentSegment.Len() > 0 {
				currentSegment.WriteString(" ")
			}
			currentSegment.WriteString(word)
		}
	}

	// æ·»åŠ æœ€åçš„æ®µè½
	if segment := strings.TrimSpace(currentSegment.String()); segment != "" {
		result = append(result, segment)
	}

	return result
}

// GetParagraphSplitStats è·å–æ®µè½æ‹†åˆ†ç»Ÿè®¡ä¿¡æ¯
func (c *ContentParser) GetParagraphSplitStats(originalParagraphs, splitParagraphs []string) map[string]interface{} {
	stats := make(map[string]interface{})

	originalCount := len(originalParagraphs)
	splitCount := len(splitParagraphs)

	// è®¡ç®—åŸå§‹æ®µè½ä¸­è¶…é•¿çš„æ•°é‡
	longParagraphsCount := 0
	totalOriginalLength := 0
	totalSplitLength := 0

	for _, p := range originalParagraphs {
		length := len(strings.TrimSpace(p))
		totalOriginalLength += length
		if length > c.config.Paragraph.MaxLength {
			longParagraphsCount++
		}
	}

	for _, p := range splitParagraphs {
		totalSplitLength += len(strings.TrimSpace(p))
	}

	stats["original_paragraph_count"] = originalCount
	stats["split_paragraph_count"] = splitCount
	stats["long_paragraphs_count"] = longParagraphsCount
	stats["paragraphs_added"] = splitCount - originalCount
	stats["average_original_length"] = 0
	stats["average_split_length"] = 0

	if originalCount > 0 {
		stats["average_original_length"] = totalOriginalLength / originalCount
	}

	if splitCount > 0 {
		stats["average_split_length"] = totalSplitLength / splitCount
	}

	stats["splitting_enabled"] = c.config.Paragraph.EnableSplitting
	stats["max_length_config"] = c.config.Paragraph.MaxLength
	stats["min_split_length_config"] = c.config.Paragraph.MinSplitLength
	stats["split_at_sentences"] = c.config.Paragraph.SplitAtSentences

	return stats
}

// LogParagraphSplitInfo è®°å½•æ®µè½æ‹†åˆ†ä¿¡æ¯
func (c *ContentParser) LogParagraphSplitInfo(stats map[string]interface{}) {
	if !stats["splitting_enabled"].(bool) {
		fmt.Println("ğŸ“ æ®µè½æ‹†åˆ†åŠŸèƒ½å·²ç¦ç”¨")
		return
	}

	originalCount := stats["original_paragraph_count"].(int)
	splitCount := stats["split_paragraph_count"].(int)
	longCount := stats["long_paragraphs_count"].(int)
	added := stats["paragraphs_added"].(int)

	if added > 0 {
		fmt.Printf("âœ‚ï¸ æ®µè½æ‹†åˆ†å®Œæˆ: %dä¸ªæ®µè½ â†’ %dä¸ªæ®µè½ (æ–°å¢%dä¸ª)\n",
			originalCount, splitCount, added)
		fmt.Printf("ğŸ“Š å‘ç°%dä¸ªè¶…é•¿æ®µè½å·²è¢«æ‹†åˆ†\n", longCount)
		fmt.Printf("ğŸ“ å¹³å‡é•¿åº¦: %då­—ç¬¦ â†’ %då­—ç¬¦\n",
			stats["average_original_length"].(int),
			stats["average_split_length"].(int))
	} else {
		fmt.Printf("ğŸ“ æ®µè½åˆ†æå®Œæˆ: %dä¸ªæ®µè½ï¼Œæ— éœ€æ‹†åˆ†\n", originalCount)
	}
}
